[{"authors":null,"categories":null,"content":"I am Ayush, currently a Master\u0026rsquo;s of Financial Engineering candidate at Haas school of Business, UC Berkeley. I completed my Bachelor\u0026rsquo;s degree from the Maths Dept. at IIT-Kanpur. I have gained skills in statistical research \u0026amp; implementation, Math, Programming and Finance through various courses, projects, internships and summer programs. I have also worked as a Technical Product Manager for the Delivery charges \u0026amp; Serviceability teams at Zomato from June 2021 to Feb 2022. I am looking to apply my skills at Quantitative roles.\nApart from this, I am extremely invested in the Financial markets, specifically in the derivative product space. I have been trading and investing for more than 2 years and would love to hear about your idea of the next big market phenomenon. Ask me anything cars or Formula 1, and I usually cannot shut up about Mclaren. I dabble with music, cooking and photography as well. Let\u0026rsquo;s get coffee!\n","date":1604707200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1604707200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://ayushmclaren.github.io/author/ayush-agarwal/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/ayush-agarwal/","section":"authors","summary":"I am Ayush, currently a Master\u0026rsquo;s of Financial Engineering candidate at Haas school of Business, UC Berkeley. I completed my Bachelor\u0026rsquo;s degree from the Maths Dept. at IIT-Kanpur. I have gained skills in statistical research \u0026amp; implementation, Math, Programming and Finance through various courses, projects, internships and summer programs.","tags":null,"title":"Ayush Agarwal","type":"authors"},{"authors":["Ayush Agarwal"],"categories":["Psychology"],"content":"Unsurprisingly Human Behavior Experiments, by director Alex Gibney, which debuted on the Sundance Channel in 2006, makes a compelling argument for the frailty of human nature. It focuses on three notorious psychology projects that demonstrate man’s inhumanity to man, the Milgram Experiment, the Columbia University study of the bystander effect, and the Stanford Prison Experiment.\nThe Milgram Obedience Experiment\n Premise and Real world instances  In the 1960s, Stanley Milgram at the Yale University, famously explored how the Nazis could have found Germans willing to carry out their barbarous crimes. He set out to study authority and explore, as he put it, \u0026ldquo;under what conditions could a person obey, when commanded, actions that went against conscience.\u0026rdquo;\nHe devised a study in which subjects delivered what they thought were painful electric jolts to a fellow participant, merely because they were encouraged to do so by the scientist in charge who assured them it was necessary for a learning experiment.\nIt was first published in the Journal of Abnormal and Social Psychology in 1963, and has earned a place as one of the most famous experiments of the 20th century. The subject (a hidden accomplice of the experimenter) describes having a mild heart condition and is strapped to the machine, while a person is instructed to punish them with increasing levels of shocks on making mistakes — about 60 percent — kept increasing the pain levels (even with the subject screaming with pain) under calm but firm instruction from the experimenter, \u0026ldquo;Continue, please.\u0026rdquo;\nThere was a lot of controversy regarding the ethics of the experiment, however, the findings are ever relevant as demonstrated by the McDonalds strip search incident. A con-man impersonating a police officer on the phone managed to convince a McDonalds manager to strip search one of her young employees, culminating in an ever greater act of sexual assault. Atleast 70 other cases of similar events were reported all across America. Now the most notable fact is that this goes a step beyond Miligram’s experiments in that the “authority” figure is not even present physically. This goes to show the sheer power of the said effect.\n Key Takeaways  The most revealing fact is that when the subject could “transfer” the responsibility onto the authority, they were suddenly free of any ethical and moral barriers to their behaviour. Some participants can even be seen hysterically laughing, enjoying the act in the process.\nCommenting on this case, Thomas Blass, Milgrim’s biographer, captured the essence with, “the mystery is not in the con man but in the victims. Why would they obey?”. One might be tempted to dismiss the behaviour as that of stupidity and irrationality, However, as Ms. Summers said in an interview, “Unless you are put in that situation at that time, how do you know what you would do? You don\u0026rsquo;t.”\nThe concrete takeaway here was one that you do not need a bunch of psychopaths to perform cruel acts and inflict serious damage onto other individuals, one can turn the most rational and innocent man into a cruel torturer.\n Avoiding behaviours  Question the authority\u0026rsquo;s legitimacy. We often give too wide a berth to people who project a commanding presence, either by their demeanor or by their mode of dress and follow their orders even in contexts irrelevant to their authority.\nWhen instructed to carry out an act you find abhorrent, even by a legitimate authority, stop and ask yourself: \u0026ldquo;Is this something I would do on my own initiative?\u0026rdquo; The answer may well be \u0026ldquo;No,\u0026rdquo; because, according to Milgram, moral considerations play a role in acts carried out under one\u0026rsquo;s own steam, but not when they emanate from an authority\u0026rsquo;s commands.\nIf you are part of a group that has been commanded to carry out immoral actions, find an ally in the group who shares your perceptions and is willing to join you in opposing the objectionable commands. In one of Milgram\u0026rsquo;s conditions the naive subject was one of a 3-person teaching team. The other two were actually confederates who-one after another-refused to continue shocking the victim. Their defiance had a liberating influence on the subjects, so that only 10% of them ended up giving the maximum shock.\nThe Bystander Effect\n Premise and Real world instances  The bystander effect is a social phenomenon that occurs when people fail to help those in need due to the presence of other people. In many cases, people feel that since there are other people around, surely someone else will leap into action.\nThe second ‘experiment’ is an illustration of diffusion of responsibility, that being where there is more than one person able to act, they will be less likely to offer assistance to someone in need. The film shows clips from experiments by John Darley and Bibb Latané at Columbia University that contrast responses to danger facing unseen others and clearly show that a herd mentality exists.\nThe infamous Kitty Genovese incident, in which nearly 40 New Yorkers watched as a woman was stabbed and crying out for help, is cited as a real-life forerunner to the experiment, and a frat hazing that resulted in manslaughter is cited as a more recent incident of this diffusion. All this to make a point about herd mentality: that people who might give help when by themselves will, among others, hold back and follow the cues of a majority. The person who goes against the group or defies authority is a rarity.\n Key Takeaways  Being part of a group often diminishes one’s sense of personal responsibility. Instead, there’s a feeling of anonymity. In this state, people are more likely to do things they would never do individually. This deindividuation, or perceived loss of individuality, is often associated with mob actions or notorious massacres. Witnesses to Kitty Genovese’s murder gave excuses such as, “I didn’t want to get involved,” and “I thought it was just a lovers’ quarrel.”\n  Avoiding behaviours\n  Witnessing Helping Behavior: Sometimes just seeing other people doing something kind or helpful makes us more willing to help others.\n  Being Skilled and Knowledgeable: When faced with an emergency situation, knowing what to do greatly increases the likelihood that a person will take action.\n  Guilt: Researchers have found that feelings of guilt can often spur on helping behaviors. So-called \u0026ldquo;survivor guilt\u0026rdquo; is just one example.\n    The Stanford Prison Experiment\n Premise and Real world instances  Dr. Zimbardo\u0026rsquo;s prison study was even more shocking. Dr. Philip Zimbardo placed 24 average men in a mock-prison, and randomly assigned them to the role of guard or prisoner, and had some pretty remarkable findings about power roles and authority. The students assigned to play guards were not instructed to be abusive, and instead conformed to their own notions of how to keep order in a prison: \u0026ldquo;Lord of the Flies\u0026rdquo; in sideburns and aviator sunglasses. The prisoners were blindfolded, stripped, assigned numbers and forced to wear skimpy hospital gowns and ankle chains. The guards were given handcuffs, whistles and billy clubs. The scientists received a shocking display of how, as one of them put it, \u0026ldquo;human nature transformed in a very rapid way in the face of a very powerful situation.\u0026rdquo;\nThe abuse kept escalating until, on the fourth day, it turned into sexual humiliation. Prisoners began breaking down. Dr. Zimbardo and his team were so engrossed by the experiment that they too lost sight of reality. In the film Dr. Zimbardo recalls that it was not until his girlfriend visited the mock prison and threatened to break up with him that he snapped out of it and ended the study early.\n Key Takeaway  The Stanford students knew they were taking part in a psychology experiment. Soldiers assigned to guard prisoners at Abu Ghraib were told that the survival of comrades on the front lines depended on whether they could break the prisoners. Dr. Zimbardo, who in 2004 served as an expert witness in the court martial of Staff Sgt. Ivan Frederick II, who was convicted of assault, indecent acts and dereliction of duty at Abu Ghraib, said he was \u0026ldquo;an ordinary good guy who gets into this place and is totally corrupted.\u0026rdquo;\nCertain environments “elicit the worst from good people” — a more complex and troubling scenario than the popular “monsters on the loose” image that dovetails with our collective desire for justice and retribution.\nThe Human Behavior Experiments is an unusual Gibney venture – it’s not focused on a small group of people, an individual or an organisation, but on humanity more broadly – and despite, or perhaps because of, its 1-hour runtime, it manages to be both informative and entertaining.\n","date":1604707200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604707200,"objectID":"8b20bbb96d1224f3a5c964c9bd91020c","permalink":"https://ayushmclaren.github.io/post/obedience/","publishdate":"2020-11-07T00:00:00Z","relpermalink":"/post/obedience/","section":"post","summary":"A note on  Human Behavior Experiments, by director Alex Gibney","tags":["Psychology"],"title":"Frailty of the human mind : The devil’s obedience","type":"post"},{"authors":["Ayush Agarwal"],"categories":["Psychology"],"content":"Scene 1: A glass with water in it. The water is at the half-way mark. Which leads to a critical question: Is the glass half empty? Or is the glass half full? What would you choose? Does it matter? After all, either of the above is true. Scene 2: You are lost in a desert, with a glass of water. The water is at the half-way mark. I urge you to go back to the same question. What would you choose now? Does it matter?\nChances are that you had a larger tendency to quantify the glass as half empty in the latter scene than the former. The objective truth remained, the glass contained water to the half-way mark. However, when we put our glass into context, something changed. A seemingly trivial binary decision turned out to have far-reaching implications. The truth itself doesn’t change, but how we interpret it can and may have a huge impact on our further actions. Seeing the glass as half full is archetypal of an optimist. She focuses on what is there, so much that can be done with the glass. On the contrary, the pessimist sees the glass as half empty. He sees that the glass used to be full, and soon he will feel the thirst. Woe is him.\nIn this time of crisis, all of us will soon have to psychologically tune ourselves to the “new normal” and the post-COVID world, if we haven’t already. One might argue, as is supported by conventional wisdom, that every crisis calls for a strategy of “optimism tempered with realism”; and intuitively “faith”, “belief” and “hope” along with other convenient abstracts make political, social and economical sense. However, there is a case to be made for the pessimists and the Eeyores of the world. Defensive pessimists, to be specific. Because when the world stops spinning, defensive pessimists will be the ones with their feet on Mars, metaphorically speaking.\nPessimism isn’t just about negative thinking, research has shown that it also includes a focus on outcomes – that is what you expect will happen in the future. While strategic optimists try to maintain a positive stance throughout, they might be prone to be guilty of fitting the events to a positive hypothesis instead of the hypothesis to the events. In the words of Julie Norem, a psychology professor at Wellesley College and a pioneer of the defensive pessimism theory, “trying to force positivity is a bad strategy for the truly anxious”.\nWhen people are being defensively pessimistic, they set low expectations, but then they take the next step which is to think through in concrete and vivid ways what exactly might go wrong. To delve a little deeper into a defensive pessimists’ mind, imagine you have to speak publicly in front of an audience. You start feeling anxious about it and start contemplating the disaster. Maybe you will trip over while walking up the stage, or knock over the coffee mug onto your dress. The microphone will malfunction, and you’ll get questions from the audience you’ve never thought of. At the first instance it seems like you’re spiraling down a tar pit and catastrophizing. However, the way this differs from a garden-variety pessimism is the constructive adaptation, and the action to safeguard against some of these items on your checklist of disasters. Defensive pessimism may not help you get rid of your anxiety, but the flip side is that it keeps your mind anchored and focuses you on things you can control. It helps you direct your anxiety towards a productive activity. In some sense, you’ve peaked in anxiety before the actual performance.\nEverything comes with caveats of its own, and in the case of pessimism, a social aspect is certainly something of interest. This tendency can severely affect relationships with people who fall in the more optimistic basket as constantly practicing it will label you as the harbinger of gloom. If you’re doing it out loud, other people tend not to like it. They tend to have questions about your competence. There’s this idea that there’s something wrong with you if all you see are problems in the world. Although it is okay for someone to just try to be happy, emotional states by definition are supposed to be transient. You’re going to be happy sometimes, and not happy sometimes. If your goal is to be happy, the next time you’re not happy, you’ll feel like you have failed. If you feel anxious and it feels real to you, ignoring it generally doesn’t work out.\nDefensive pessimism, of course, is not for everyone. Those vulnerable to acute and frequent bouts of anxiety must not look for vindication in negative thinking. You are getting worked up in the process, it takes energy. If you’re doing it for everything, you’re more likely to wear yourself out. That said, anxiety is exhausting anyway. But, for a large number of us who keep bouncing between radically contrasting versions of emotional extrema, defensive pessimism provides a path that challenges the herd mentality who advocate positivity for the sheer sake of it.\nOne could argue that defensive pessimism is, at this moment, not just sensible but the need of the hour. When we heard of the lockdowns, all of us rushed to get the essential supplies stocked up on the eventuality of a shortage. Because we assumed the worst, we actually got off and did something about it. I think the real edge a defensive pessimist might have when the world reopens is that they will continue to take more precautions, and prepare for the roller coaster of peaks that may happen. They’re less likely to be caught off guard by any of it.\nDefensive pessimism does not view the future through rose coloured glasses. It sees a post-pandemic planet not as a return to paradise but as a place that is still prone to pitfalls and prejudices, and thus warrants strict caution. By making us aware that things can go wrong at every turn, defensive pessimism is perfect in the sense that a lot of our current misery is directly a product of our seemingly proud all-knowing ego, and the cultural euphoria that everything would always eventually be alright.\nIt will take all sorts to make the desert ahead survivable in case you do actually get lost. However, the foresight of packing an extra bottle and anticipating the eventuality that water might run out seems better on face value than holding out to the hope that we will run into an oasis before the “half full” glass runs out. There’s no correct way to think about things that fit every situation and every person. You will have to find your own ways in the world. The real reason thinking positively can work well is because it motivates people to go out and make the change. If thinking positively leads you to productive action, that’s great. But it doesn’t for everyone. All this to say that we shouldn’t count the pessimists out. Optimism, as we’ve seen, can turn dangerously into self-delusion pretty quickly. Indulging in it too frequently might leave us with nothing to fight for.\n","date":1604188800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604188800,"objectID":"ff53ee12fd482064ef57ec8642e5b74f","permalink":"https://ayushmclaren.github.io/post/pessimism/","publishdate":"2020-11-01T00:00:00Z","relpermalink":"/post/pessimism/","section":"post","summary":"What would you choose to be and does it even matter?","tags":["Psychology"],"title":"The case for Pessimism and the half empty glass","type":"post"},{"authors":["Ayush Agarwal","Dootika Vats"],"categories":null,"content":"","date":1599782400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599782400,"objectID":"c96cda0f07b49233da2fa24ac1fbe169","permalink":"https://ayushmclaren.github.io/publication/qbld/","publishdate":"2020-09-11T00:00:00Z","relpermalink":"/publication/qbld/","section":"publication","summary":"Implements the Bayesian quantile regression model for binary longitudinal data (QBLD) developed in Rahman and Vossmeyer (2019).","tags":["Quantile regression","MCMC","R Project for Statistical Computing"],"title":"qbld: Quantile regression for binary longitudinal data","type":"publication"},{"authors":null,"categories":null,"content":"Introduction We propose a novel change-point algorithm for the MCMC setup. In particular, we show how procedures based on the cumulative sum, CUSUM, statistics can be modified to work for data exhibiting serial dependence such as a Markov Chain. This allows us to find mean structural breaks under a non-parametric framework, without any strong assumptions on the underlying distribution. We argue that this helps us identify the ideal \u0026ldquo;burn-in\u0026rdquo; period for the chain, and subsequently improves the MCMC estimates.\nLiterature Review The existing literature on a non-parametric change point analysis is wide, however, a discussion on using change-point methods to identify the initial \u0026ldquo;transient\u0026rdquo; (or \u0026ldquo;burn-in\u0026rdquo;) period seems to be missing. In particular, the methods based on the CUSUM max-type statistics described in Aue and Horv́ath (2013) suffer from a few major shortcomings as described below.\n  The CUSUM method described is \u0026ldquo;offline\u0026rdquo; in the sense that while we\u0026rsquo;re dealing with sequential data, the chain is not processed in a strictly sequential (or \u0026ldquo;online\u0026rdquo;) sense. Max-type statistics that operate on the whole chain generally identify the most significant change-point rather than the first significant one. Hence, we require methods that are tuned to identify change-point in the initial part of the chain.\n  The power of a max-type statistic is maximum when the two fragments of data are of roughly equal size and is significantly affected when we move to either side.\n  Another cause for concern in hypothesis based testing is the assumption of stationarity as the null hypothesis. These methods require the estimation the long-run variance-covariance matrix under the stationarity assumption. However, the chain is often not stationary; the estimates are biased and tend to affect the performance of the test.\n  Another potential source of error are multivariate chains with high correlation among components. Normalising CUSUM by the covariance estimator tends to bias the change-point towards the faster converging components.\n  To summarize, a method that is robust to changes after the first significant change-point, avoids hypothesis based testing and variance estimation is of interest.\nFor more information, check out the code and pdf, accessible via the buttons on the top.\n","date":1598918400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598918400,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"https://ayushmclaren.github.io/project/internal-project/","publishdate":"2020-09-01T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"Change-point Detection in Markov chains for identifying burn-in period","tags":["MCMC"],"title":"Changepoint algorithm for MCMC","type":"project"},{"authors":["Ayush Agarwal"],"categories":["Psychology"],"content":"Validity of Sternberg’s Additive factors method. The Sternberg Task and Serialisation\n  The experiment entails memorization of a positive set, a list of items such as numbers or words.\n  The subject is then asked about a particular test item that may or may not have actually been present in the set, and is asked to respond \u0026ldquo;yes\u0026rdquo; or \u0026ldquo;no\u0026rdquo; accordingly.\n  The time taken for the subject to respond is recorded. This process is then repeated over several trials. What Sternberg found was that response time tended to increase with the size of the list. This provided evidence for Serial and Exhaustive Search Theory, which proposes that people will search every item in an array without stopping, even if the item was found.\n    Overarching consensus\n  This is the general underpinning of his additive factors method. This is a method that uses reaction time measured over a range of tasks in order to identify different cognitive processing stages. He argues that the indications for serial processing stages result either from a single processor switching from one to the next processing stage, or from one processor waiting for the output of another processor.\n  Serial processing models have been refuted in the past because they would not acknowledge parallel processes and feedback loops. Also, they would not account for tasks in which stimuli prime response movements in unintended ways (like Stroop task).\n  Hence, there have been studies that demonstrate additive factors can be successfully accounted for by existing single stage models of the Stroop effect. The Stroop task is ideal for this comparison because it uses both the perceptual representations (perceiving the colour of the word) and cognitive elements (representation,concept of the words and colours in our mind) to produce a correct response. Hence, if we can show that a discrete model is not necessary or can be accounted for by continuous processes, we essentially argue that a differentiation and demarcation of processing in the brain is not apparent.\nEmpirical results of the stroop task as below.\n  The Additive Factors Method\nAccording to the assumptions of the AFM, independent components – “stages” – of decision making are revealed by the analysis of how different factors affect reaction times. Hence, if change in one factor affects Reaction Times independently of the change of another factor, then it is concluded that the two factors affect different stages of decision making.\nThus in this way, AFM provides a framework to assess the minimum number of independent processes (or steps) that are involved in decision making. This method has supported the independence of stimulus processing and response selection. However, the AFM method can only point to the algorithmic level of choice reactions, not the implementational level as described in Marr’s Tri-level approach.\nThe Additive Factors Method - Assumptions\n  Measuring a single small unit can be accomplished by measuring a large, known quantity of small units then dividing by the number of units. For example, to measure the thickness of a single sheet of paper with an ordinary ruler, measure the thickness of a stack of paper sheets, then divide by the number of sheets.\n  The total time to complete a response is literally the sum of the times of separate processing steps. Thus, if it takes 200 msec to complete visual decoding, 300 ms to complete scanning, and 500 ms to make a detectable response, the total time to respond is 200 + 300 + 500, or 1000 ms.\n  Some individual processing steps, such as pressing a response key, take the same amount of time regardless of the amount of information to be scanned. For example, if response execution takes 500 ms when scanning 1 item, it should only take 500 ms when scanning 4 items. The times for steps that stay the same can be treated as constants.\n  Basic Critique\nThomas (2006) shows that AFM can predict interaction of factors once reasonable assumptions about the representation is taken into account. In contrast, Parallel Distributed Processing (PDP) framework suggests information being continuously available and interactively processed across multiple locations. McClelland (1979) showed that such a PDP “continuous processing” model could produce results which were consistent with the AFM, despite the lack of the discrete serial modules that the AFM is usually assumed to imply. Let us now, come back to the stroop task, compare and contrast the continuous with discrete models to comment on the serialization.\nContinuous Stage Models - Cohen et al\nThe basic idea is that to activate an associated response code, a stimulus code needs to be translated into the response (As long as the primary response is not selected).\nThe essence of the model is that it evaluates using a distribution network, the word and color information in the stimulus and “responds based on the ink color, ignoring the word”. The weights of these factors and their combination, leads to the response, which signals the selected response. It does this after a certain amount of evidence, from all units in the model, has been accumulated. This model is a continuous processing model. Activity in all parts of the model is continuously updated as the effect of the change in inputs propagates. Although this may have many architectural stages, all components are running simultaneously and passing information without delay to each other.\nNow for Stroop, In this model, the word and color information is represented by 0 or 1 values. The stimulus color, say, was red, the input unit for “red” would be restricted at 1 and the input unit for green would be restricted at 0. To simulate intermediate intensity, values between 0 and 1 were used. Both the color and the word input values were restricted at the same intermediate values, namely 0.2, 0.4, 0.6, 0.8, or 1.0. This reflects the corresponding variation in the strength of the input representation with varying color saturation.\n  Discrete Stage Models - Two stage\nA two stage, discrete processing variant of the Cohen model is constructed by adding a “detection” stage. This stage delays inputs to the second stage and until this output is passed, no other processing can take place. The influence of color saturation is incorporated by providing continuously valued inputs to the detection stage only.\n  The interference effect is larger than the facilitation effect across all stimulus intensity values, and that both effects are consistent across all stimulus intensity values. Note, however, that this is not logically sufficient to justify the inference of discrete stages from additive factors in the response times.\nNote that in accordance with AFM, the stimulus intensity only affects processing in the first stage, and the Stroop condition only affects processing in the second stage.\nConsequences for Decision Making\nThe essence is that single stage models of decision making will be useful at the data-descriptive level and for defining optimality, but multistage models will be required to account for experimental situations where decision making departs from optimality. The models presented here suggest that the simple decision making models developed to account for simple perceptual decisions cannot alone be a complete model of decision making. Without assumptions about other elements of perception and action selection, simple response mechanisms are insufficient to account for empirical data once the scope of decision making moves beyond the simple perception.\nFunctional vs Structuralist approach to Reaction Times\nWhen an RT paradigm is used, the experimenter is usually interested in the mechanism that accounts for the time that passes between stimulus and response, commonly denoted by the term latency. It is assumed that this mechanism induces a characteristic, stationary probability distribution on RT. Globally, the various approaches to the decomposition of RT can be reduced to two major trends: the functionalist approach and the structuralist approach.\nThe functionalist approach to RT originates in its recent form from the work of Sternberg (1966, 1969). The reasoning behind Sternberg\u0026rsquo;s method is (a) that the stimulus-response process consists of a number of serial stages and (b) that different stages perform different functions. In a way, this approach takes its starting point at the level of studying the effects of various experimental conditions and from there seeks conclusions concerning the components of the stimulus-response process.\nOriginally Sternberg (1966, 1969) postulated four stages: stimulus encoding, information processing and evaluation, response decision, and response selection and evocation. Sanders (1980) already postulates six stages based on a review of the RT literature: stimulus preprocessing, feature extraction, identification, response choice, response,programming, and motor adjustment.\nIdeally, a stage has the following four properties: (a) for a given input, the output is unaffected by factors influencing its duration; (b) a stage is a functional entity that is psychologically and qualitatively different from other stages; (c) one stage can process only one signal at a time; (d) stage durations are stochastically independent.\nThe main theoretical difference between the functionalist and the structuralist approach lies in the specification of the underlying stochastic mechanism. This mechanism is completely specified in the structuralist approach, whereas in the functionalist approach one only makes some general assumptions regarding the mean and variance of the response process. For this reason, the structuralist approach is also referred to as the model or distributional approach, and the functionalist approach is commonly referred to as stage analysis of RT. The structural approach starts from specific assumptions about the stochastic mechanisms involved and from there derives predictions concerning relevant aspects of the process. In general, the objective of research efforts should be to describe, to predict, and to explain the phenomena we deal with. The functionalist approach asks essentially: \u0026ldquo;Which variables have an effect, and do they interact?\u0026rdquo; whereas the structuralist or model approach asks: \u0026ldquo;What are the processes involved, and how do the variables affect these processes?\u0026rdquo;\n  Embodied Cognition and Evolution of Language Historical Overview\nHow language conveys meaning remains an open question. The dominant approach is to treat language as a symbol manipulation system: Language conveys meaning by using abstract, amodal, and arbitrary symbols (i.e.words) combined by syntactic rules (e.g. Chomsky,1980; Fodor,2000; Pinker,1994). Words are abstract in that the same word, such as “chair” is used for big chairs and little chairs, words are amodal in that the same word is used when chairs are spoken about or written about, and words are arbitrarily related to their referents in that the phonemic and orthographic characteristics of a word bear no relationship to the physical or functional characteristics of the word’s referent.\nA natural language is a structured symbolic system that involves a systematic mapping between a virtually unbounded set of thoughts and a virtually unbounded set of sounds or manual gestures. Given our limited cognitive abilities, it is common to explain linguistic competence in terms of a ﬁnite set of stored lexical units or complexes and combinatorial principles.\nAn alternative view is that linguistic meaning is grounded in bodily activity. Cognitive Linguistics has used the notion of embodiment to explain facts about language since its inception. There have been three distinct phases in the application of the idea of embodiment to empirical work on language and cognition.\nThe first was analytical in that it involved linguists − inspired by work in cognitive psychology − looking for evidence of how the conceptual resources that underlie language use might be embodied through analysis of language. Work in this stage produced results that did not speak much to mechanisms, and as a result were equally compatible with the developmental and online types of embodiment.\nThe second phase is the process phase, which involved refinement of the online version of embodiment in a way that has generated a new theoretical framework, and inspired a substantial body of empirical work.\nAnd the third phase is the function phase, in which researchers are refining their tools in an effort to determine exactly what embodiment does for specific aspects of language use and other cognitive operations.\nHowever, abstract concepts such as DEMOCRACY, ENTROPY, JUSTICE, NUMBER, and TRUTH are a critical issue for embodied cognition because it is difﬁcult to see how they can be captured by representations grounded in sensorimotor systems. There have been notable attempts to address this problem, including appeals to metaphoric extension.\nMetaphors - Could the future taste purple?\nWhen producing speech, people usually generate an impressive amount of spontaneous gestures, bodily postures, and facial expressions. More precisely, people produce, in a perfectly synchronized manner spontaneous gestures which somehow match the meaning, timing, and form of the oral expressions used.\nFor instance, with a hand or a finger, people point towards something in their backs at the very moment when they say ‘all the way back in the thirties’. Or they show something in front of them when saying ‘the days ahead of us’. Therefore, bodily actions (i.e., spontaneous gestures) and speech, not only are coherent, but occur with an impressive synchronicity with speech.\nIt has been shown that an important amount of abstract thought is unconscious (i.e. it happens below the level of awareness and therefore is often beyond introspection), and it has shown that concepts are systematically organized through everyday cognitive mechanisms such as conceptual mappings. The most well known conceptual mappings are conceptual metaphors (Lakoff and Johnson, 1980).\nA conceptual metaphor is a cognitive mechanism that allows us to make precise inferences in one domain of experience (target domain) based on the inferences that hold in another domain (source domain). Through this mechanism, the target domain is understood, often unconsciously, in terms of the inferential structure that holds in the source domain. A conceptual metaphor, as understood in cognitive linguistics, does not belong to the realm of words but to the realm of thought. And this is very important to keep in mind: a conceptual metaphor is a cognitive mechanism, an inference-preserving cross-domain mapping. Particularly relevant is the distinction between time-based metaphors and ego-based metaphors.\n  The Blank Screen Paradigm\nThe ‘visual world paradigm’ typically involves presenting participants with a visual scene and recording eye movements as they either hear an instruction to manipulate objects in the scene or as they listen to a description of what may happen to those objects. In this study, participants heard each target sentence only after the corresponding visual scene had been displayed and then removed.\nFor a scene depicting a man, a woman, a cake, and a newspaper, the eyes were subsequently directed, during ‘eat’ in ‘the man will eat the cake’, towards where the cake had previously been located even though the screen had been blank for over 2 s. The rapidity of these movements mirrored the anticipatory eye movements observed in previous studies. Thus, anticipatory eye movements are not dependent on a concurrent visual scene, but are dependent on a mental record of the scene that is independent of whether the visual scene is still present.\n  Why did the eyes move to a particular location when there was nothing there? One possibility is based on the idea that very little information about one part of a visual scene is maintained internally when the eyes move to another part. Richardson and Spivey (2000) proposed, following O’Regan (1992), that the visual system instead uses the scene itself as an external memory, using oculomotor coordinates (defined relative to the configuration of cues within the scene) as pointers towards this external memory. The activation of these pointers causes the eyes to move to the corresponding coordinate from where information about the contents of that part of the scene can be retrieved.\n  In conclusion: Eye movements that are triggered during linguistic expressions are not contingent on an item being co-present with that expression. Thus, even when the visual scene is concurrent with a linguistic expression that refers to an item within that scene, information about where to move the eyes in order to fixate that item may be based not on the actual location of that item within the scene, but on the location of that item as represented within a mental representation of the scene.\nGrounding Action in Language - Glenberg\nThis demonstrates that merely comprehending a sentence that implies action in one direction (e.g.,“Close the drawer” implies action away from the body) interferes with real action in the opposite direction (e.g., movement toward the body). These data are consistent with the claim that language comprehension is grounded in bodily action, and they are inconsistent with abstract symbol theories of meaning.\nExperiment :-\nParticipants were presented with a series of sensible and nonsense sentences, and they were asked to determine as quickly as possible whether each sentence made sense. One independent variable, implied sentence direction (toward/away), was manipulated for the sensible sentences. Thus, toward sentences, such as “Open the drawer” and “Put your finger under your nose”, implied action toward the body. A way sentences, such as “Close the drawer” and “Put your finger under the faucet,” implied action away from the body.\nThe nonsense sentences, such as “Boil the air,” did not seem to imply any direction. Note that the participants were never instructed to consider the implied direction; their task was merely to judge sensibility. The actual response direction (yes-is-near/ yes-is-far) was manipulated by using a specially constructed button box.\nAccording to the study, meaning is action-based: Understanding a toward sentence requires meshing affordances (e.g., of a drawer and the action of opening), resulting in a simulation of actions toward the body, whereas understanding an away sentence results in a simulation of actions moving away from the body. If this simulation requires the same neural systems as the planning and guidance of real action, understanding a toward sentence should interfere with making a movement away from the body to indicate yes (yes-is-far), and vice-versa. This is called the Action Congruency Effect.\nHalf of the 80 sensible sentence pairs (toward/away pairs) were in the imperative, such as the examples above. The other half of the sensible sentence pairs described a type of transfer. The concrete transfer pairs described a physical transfer. Half of these used the double-object construction (e.g., “Courtney handed you the notebook/ You handed Courtney the notebook”), and half used the dative form (e.g., “Andy delivered the pizza to you/ You delivered the pizza to Andy”). The 20 abstract transfer pairs described a nonphysical transfer, such as “Liz told you the story/ You told Liz the story” and “The policeman radioed the message to you/You radioed the message to the policeman.”\n    Inseparability Principle/SLA - Atkinson\nThree SLA principles based on extended, embodied cognition:\n The Inseparability Principle: Mind, body, and world work together in learning/SLA; The Learning-is-adaptive Principle: Learning/SLA facilitates survival and prosperity in complex environments; and The Alignment Principle: A major engine of learning/SLA is alignment, the means by which we effect interaction.  The Inseparability Principle and SLA\nConsider four questions vis-a-vis the picture below,\n Who is the person in the picture? What is she doing? Where and when? Why?  The aim of this exercise is to suggest that SLA is more than just a cognitive input/restructuring/output process, and what some of that ‘more’ may be.\n  This pictorial illustration has three implications for SLA. First, it suggests that people cognize/learn not just mentally, but in environments composed of bodies, cognitive tools, social practices, and environmental features. If, as the inseparability principle argues, such contexts crucially affect cognition/learning, then they cannot be treated as optional extras. Regarding learning this suggests that:\n Learning is more discovering how to align with the world than extracting knowledge from it (Ingold 2000); and By being environmentally embedded, knowledge/cognition is made public and thereby learnable.  The second implication of this illustration concerns the quality of cognition/learning (van Lier 2002). The personal relationships learning involves, its role in identity construction (Norton 2000), where and under whose sponsorship it occurs, and how it is embodied and enacted fundamentally influence its outcome. Unlike computers, humans don’t just process—they find value and meaning. This affects learners’ engagement with learning opportunities, including whether they engage at all.\nThird, if cognition/learning is complex and multimodal, as the illustration suggests, then it must be studied complexly and multimodally.\nThe learning-is-adaptive principle and SLA\nThe learning-is-adaptive principle has four linked implications for learning/SLA:\n Learning/SLA is relational: Learning-as-adaptive-behavior concerns how to relate—how to articulate with one’s environment. Learning/SLA is experiential, participatory, and guided: One learns to relate by relating - learning is experiential. Learning/SLA is public: One crucial way learning is guided is by externalizing its object while focusing the learner’s attention (Schmidt 2001) on it. Learning/SLA is aligning, and learning to align: This final point summarizes the preceding three: Learning is a process of alignment—of continuously and progressively fitting oneself to one’s environment, often with the help of guides.  The alignment principle and SLA\nFirst, it means having formidable pre-existing capacities for interacting without necessarily sharing a language. That is, all language learners have powerful interaction engines supporting their learning at every turn.\nSecond, SLA itself is a process of alignment—of learning the ‘differences that make a difference’ (Bateson 1972: 459) in the L2 environment. This is what our guides teach us as we engage with the environment: A requisite idiom or formula here, a form-function relationship there—to do that, you need to say this. By trying to align with our environment—by learning to behave in eco socially adaptive ways—we become ‘enskilled’ (Ingold 2000: 5).\nThird, as noted above, alignment has a public face: Our aligning/learning behaviors extend into the world, and as our guides facilitate and respond to them, alignment is further externalized. Ultimately, sociocognitive approaches to SLA are based on this tripartite premise: (i) Mind, body, and world are in continuous processes of interactive alignment; (ii) These processes are partly public; and (iii) In being public, they are learnable. Thus, if cognition is the site of learning, it is extended, embodied cognition that makes learning possible, at least in part.\n","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"9ef25844d42e46dc5efbfe230b0d3124","permalink":"https://ayushmclaren.github.io/post/cpandl/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/post/cpandl/","section":"post","summary":"A note on Sternbergs technique and evolution of language through embeded cognition","tags":["Psychology"],"title":"On concept, perception and language","type":"post"},{"authors":null,"categories":null,"content":"","date":1585699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585699200,"objectID":"63f337dbcd9daef67d0965161bc7e1af","permalink":"https://ayushmclaren.github.io/project/external-project2/","publishdate":"2020-04-01T00:00:00Z","relpermalink":"/project/external-project2/","section":"project","summary":"Bayesian Structural Time Series Analysis of Airplanes and IncomeAnalysis Data","tags":["Bayesian Stats","Time Series"],"title":"BSTS","type":"project"},{"authors":["Ayush Agarwal"],"categories":null,"content":"  ","date":1583341200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583341200,"objectID":"facaea0f129bd0366f07d0cb2624627d","permalink":"https://ayushmclaren.github.io/talk/mh/","publishdate":"2020-03-04T19:00:00Z","relpermalink":"/talk/mh/","section":"talk","summary":"This paper presents a method for adaptation in Metropolis–Hastings algorithms.","tags":["MCMC"],"title":"Adaptive Metropolis–Hastings methods","type":"talk"},{"authors":["Ayush Agarwal"],"categories":["Psychology"],"content":"Limitations of Classic Model of Cognition that embodied cognition addresses Traditionally, cognitive science has viewed the mind as an abstract information processor, whose connections to the outside world were of little theoretical importance. Perceptual and motor systems, were thought to serve merely as peripheral input and output devices, and were not considered relevant to understanding “central” cognitive processes.\nThe Computational Theory of Mind combines an account of reasoning with an account of the mental states. This is the thesis that intentional states such as beliefs and desires (propositional attitudes) are relations between a thinker and symbolic representations of the states. These representations have both semantic and syntactic properties and reasoning is responsive only to the syntax of the symbols\u0026ndash;is known as ‘formal symbol manipulation’. One such system of rules that may be used is propositional logic.\nFor example, to believe that there is a dog on the rug is a particular functional relation (characteristic of the attitude is that of belief) to a symbolic mental representation whose semantic value is \u0026ldquo;there is a dog on the rug\u0026rdquo;; Similarly, to hope that there is a dog on the rug is a different functional relation (characteristic of the attitude of hoping) to a symbolic mental representation with the same semantic value. Two of the most cited classical approaches are Fodor’s, ‘Language of thought(LoT)’, and Marr\u0026rsquo;s, “Three Levels”.\nThe language of thought hypothesis (LoTH) proposes that thinking occurs in a mental language. Often called Mentalese, the mental language resembles spoken language in several key respects: it contains words that can combine into sentences; the words and sentences are meaningful; and each sentence’s meaning depends in a systematic way upon the meanings of its component words and the way those words are combined. It claims that Mentalese contains analogues to the familiar logical connectives (and, or, not, if-then, some, all, the). Iterative application of logical connectives generates complex expressions from simpler expressions. However, it has a very limited scope concerning only propositional attitudes and the mental processes in which they figure, such as deductive inference, reasoning, decision-making, and planning. It does not address perception, motor control, imagination, dreaming, pattern recognition, linguistic processing, or any other mental activity distinct from high-level cognition.\nMarr\u0026rsquo;s three levels of analysis promotes the idea that complex systems such as the brain, a computer or human behaviour should be understood at different levels. Marr\u0026rsquo;s three levels are:\n  Computational At this level we describe and specify the problems we are faced with in a generic manner, but do not say how these problems are to be solved.\n  Algorithmic This level forms a bridge between the computational and implementational levels, describing how the identified computational problems can be solved.\n  Implementational The mechanism, and its organisation, in which computation is performed. This is biological like neurons and synapses.\n  Limitations to Classical approach:\n Does syntax explain semantics?  Putnam (1980) pointed out a major obstacle to such a view. It stems from a consequence of the Lowenheim-Skolem theorem in logic, from which it follows that every formal symbol system has at least one interpretation in number theory. This being the case, take any syntactic description D of Mentalese. Because our thoughts are not just about numbers, a canonical interpretation of the semantics of Mentalese (call it S) would need to map at least some of the referring terms onto non-mathematical objects. However, Lowenheim-Skolem assures that there is at least one interpretation S* that maps all of the referring terms onto only mathematical objects. S* cannot be the canonical interpretation, but there is nothing in the syntax of Mentalese to explain why S is the correct interpretation and S* is not. Therefore syntax underdetermines semantics. *\n Are all of our cognitive abilities formalizable and computable?  The oldest argument is due to J.R. Lucas (1961), who has argued that Gödel\u0026rsquo;s incompleteness theorem poses problems for the view that the mind is a computer. A distinct line of argument was developed by Hubert Dreyfus (1972). Dreyfus argued that most human knowledge and competence \u0026ndash; particularly expert knowledge \u0026ndash; cannot in fact be reduced to an algorithmic procedure, and hence is not computable in the relevant technical sense. The novice chess player might follow rules like \u0026ldquo;on the first move, advance the King\u0026rsquo;s pawn two spaces\u0026rdquo;, \u0026ldquo;seek to control the center\u0026rdquo;, and so on. But following such rules is precisely the mark of the novice. The chess master simply \u0026ldquo;sees\u0026rdquo; the \u0026ldquo;right move\u0026rdquo;. There at least seems to be no rule-following involved, but merely a skilled activity.\n Is computation sufficient for understanding?  The most influential criticism of CTM has been John Searle\u0026rsquo;s (1980) thought experiment known as the \u0026ldquo;Chinese Room\u0026rdquo;. In this thought experiment, a human being is placed in the role of the CPU in a computer. He is placed inside of a room with no way of communicating with the outside except for symbolic communications that come in through a slot in the room. These are written in Chinese, and are meaningful inscriptions, albeit in a language he does not understand. His task is to produce meaningful and appropriate responses to the symbols he is handed in the form of Chinese inscriptions of his own, which he passes out of the box. In this task he is assisted by a rulebook, containing rules for what symbols to write down in response to particular input conditions. This set-up is designed to mimic in all respects the resources available to a digital computer: it can receive symbolic input and produce symbolic output, and it manipulates the symbols it receives on the basis of rules that are such that they can be applied on non-semantic information like syntax and symbol shape alone. The only difference in the thought experiment is that the \u0026ldquo;processing unit\u0026rdquo; applying these rules is a human being.\nWhat does it mean to say that cognition encompasses the environment? Enter the idea of embodied cognition. The emerging viewpoint of embodied cognition holds that cognitive processes are deeply rooted in the body’s interactions with the world. The belief is that our bodies and their perceptually guided motions through the world do much of the work required to achieve our goals, replacing the need for complex internal mental representations. This simple fact utterly changes our idea of what “cognition” involves, and thus embodiment is a completely different theory.\nEmbodied cognition encompasses the environment through some of the claims underlying the theory as presented below:-\n We off-load cognitive work onto the environment:  Because of limits on our information-processing abilities (e.g., limits on attention and working memory), we exploit the environment to reduce the cognitive workload. We make the environment hold or even manipulate information for us, and we harvest that information only on a need-to-know basis. Humans are not entirely helpless when confronting the representational bottleneck, and two types of strategies appear to be available when one is confronting on-line task demands. The first is to rely on preloaded representations acquired through prior learning. Consider the example of counting on one’s fingers. It can be done more subtly, differentiating the positions of the fingers only enough to allow the owner of the fingers to keep track. To the observer, this might look like mere twitching. Imagine, then, that we push the activity inward still further, allowing only the priming of motor programs but no overt movement. If this kind of mental activity can be employed successfully to assist a task such as counting, a new vista of cognitive strategies opens up.\nWhat about novel stimuli and tasks, though? In these cases there is a second option, which is to reduce the cognitive workload by making use of the environment itself in strategic ways—leaving information out there in the world to be accessed as needed, rather than taking time to fully encode it. The environment can also be used as a long-term archive, as in the use of reference books, appointment calendars, and computer files. This can be thought of as off-loading to avoid memorizing, which is subtly but importantly different from off-loading to avoid encoding or holding active in short-term memory what is present in the immediate environment. Kirsh and Maglio (1994), as noted earlier, have reported a study involving the game Tetris, in which falling block shapes must be rotated and horizontally translated to fit as compactly as possible with the shapes that have already fallen. The decision of how to orient and place each block must be made before the block falls too far to allow the necessary movements. The data suggest that players use actual rotation and translation movements to simplify the problem to be solved, rather than mentally computing a solution and then executing it. Glenberg and Robertson (1999) have experimentally studied one such example, showing that in a compass-and-map task, subjects who were allowed to indexically link written instructions to objects in the environment during a learning phase performed better during a test phase than subjects who were not, both on comprehension of new written instructions and on performance of the actual task.\n The environment is part of the cognitive system: The information flow between mind and world is so dense and continuous that, for scientists studying the nature of cognitive activity, the mind alone is not a meaningful unit of analysis. The thesis of extended cognition is the claim that cognitive systems themselves extend beyond the boundary of the individual organism. On this view, features of an agent\u0026rsquo;s physical, social, and cultural environment can do more than distribute cognitive processing: they may well partially constitute that agent\u0026rsquo;s cognitive system.  Consider three cases of human problem-solving. Clark(1998)\n A person sits in front of a computer screen which displays images of various two-dimensional geometric shapes and is asked to answer questions concerning the potential fit of such shapes into depicted \u0026lsquo;sockets\u0026rsquo;. To assess fit, the person must mentally rotate the shapes to align them with the sockets. A person sits in front of a computer screen, but this time can choose either to physically rotate the image on the screen, by pressing a rotate button, or to mentally rotate the image as before. We can also suppose, not unrealistically, that some speed advantage accrues to the physical rotation operation. Sometime in the cyberpunk future, a person sits In front of a computer screen. This agent, however, has the benefit of a neural implant which can perform the rotation operation as fast as the computer in the previous example. The agent must still choose which internal resource to use the implant or the good old-fashioned mental rotation), as each resource makes different demands on attention and other concurrent brain activity.  How much cognition is present in these cases? We suggest that all three cases are similar. Case (3) with the neural implant seems clearly to be on a par with case (1). And case (2) with the rotation button displays the same sort of computational structure as case (3), distributed across agent and computer instead of internalized within the agent. If the rotation in case (3) is cognitive, by what right do we count case (2) as fundamentally different? We cannot simply point to the skin/skull boundary as justification, since the legitimacy of boundary is precisely at the issue.\nAre problems with the idea of understanding cognition as extended across the environment? The claim is this: The forces that drive cognitive activity do not reside solely inside the head of the individual, but instead are distributed across the individual and the situation as they interact. Therefore, to understand cognition we must study the situation and the situated cognizer together as a single, unified system.\nThe first part of this claim is trivially true. Causes of behavior are surely distributed across the mind plus environment. More problematic is the fact that causal control is distributed across the situation is not sufficient justification for the claim that we must study a distributed system. Science is not ultimately about explaining the causality of any particular event. For a set of things to be considered a system in the formal sense, these things must be not merely an aggregate, a collection of elements that stand in some relation to one another (spatial, temporal, or any other relation). From this description, though, it should be clear that how one defines the boundaries of a system is partly a matter of judgment and depends on the particular purposes of one’s analysis. Thus, the sun may not be part of the system when one considers the earth in biological terms, but it is most definitely part of the system when one considers the earth in terms of planetary movement.\nThe organization of a system —the functional relations among its elements, and indeed the constitutive elements themselves—would change every time the person moves to a new location or begins interacting with a different set of objects. That is, the system would retain its identity only so long as the situation and the person’s task orientation toward that situation did not change. Such a system would clearly be a facultative (temporary) system, and facultative systems like this would arise and disband rapidly and continuously during the daily life of the individual person.\nThe distributed view of cognition thus trades off the obligate (permanent) nature of the system in order to buy a system that is more or less closed.\nIf, on the other hand, we restrict the system to include only the cognitive architecture of the individual mind or brain, we are dealing with a single, persisting, obligate system. The various components of the system’s organization— perceptual mechanisms, attentional filters, working memory stores, and so on—retain their functional roles within that system across time. The system is undeniably open with respect to its environment, continuously receiving input that affects the system’s functioning and producing output that has consequences for the environment’s further impact on the system itself. Given this analysis, it seems clear that a strong view of distributed cognition—that a cognitive system cannot in principle be taken to comprise only an individual mind—will not hold up.\n","date":1579996800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579996800,"objectID":"45359097c0fbff8f34ade3afdc5ae897","permalink":"https://ayushmclaren.github.io/post/embodied/","publishdate":"2020-01-26T00:00:00Z","relpermalink":"/post/embodied/","section":"post","summary":"A note on limitations of Classic Model of Cognition that embodied cognition hopes to answer","tags":["Psychology"],"title":"On embodied cognition","type":"post"},{"authors":null,"categories":null,"content":"","date":1559865600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559865600,"objectID":"b56f4385107e18de8547fc417c064100","permalink":"https://ayushmclaren.github.io/project/external-project6/","publishdate":"2019-06-07T00:00:00Z","relpermalink":"/project/external-project6/","section":"project","summary":"A deep dive into the world of options!","tags":["Finance"],"title":"Let's talk options","type":"project"},{"authors":null,"categories":null,"content":"","date":1559347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559347200,"objectID":"028aa3b724e7547840459c1171d3cbbb","permalink":"https://ayushmclaren.github.io/project/external-project4/","publishdate":"2019-06-01T00:00:00Z","relpermalink":"/project/external-project4/","section":"project","summary":"A look into the contango vs backwardation markets, and stakeholders of the oil industry","tags":["Finance"],"title":"A Peak into the Oil Industry","type":"project"},{"authors":["Ayush Agarwal"],"categories":["Psychology"],"content":"Problem Statement :- Is Happiness a matter of ‘choice’ ? Choice here represents the number of options from which a person has to choose from. The following experiment studies the Effect of the number of choices presented to an individual to choose from on satisfaction of the individual.\nIntroduction to the Paradigm :- Barry Schwartz suggested that as options are added within a domain of choice, three problems materialize.\n First, there is the problem of gaining adequate information about the options to make a choice. Second, there is the problem that as options expand, people’s standards for what is an acceptable outcome rise. And third, there is the problem that as options expand, people may come to believe that any unacceptable result is their fault, because with so many options, they should be able to find a satisfactory one.  Similar problems arise as choice becomes available in domains in which previously there was no choice.\nConsider the different effects that an expanding array of options might have on two people, one of whom aims to maximize his or her outcomes in that domain and one of whom aims to satisfice. For the maximizer, added options pose problems. One cannot be sure that one is making the maximizing choice without examining all the alternatives. And if it is impossible or impractical to examine all the alternatives, then when the maximizer gives up the search and chooses, there will be a lingering doubt that he or she could have done better by searching a bit more. Thus, as options proliferate, the likelihood of achieving the goal of maximization goes down.\nFurther, the potential for regret is ever present, because the question the maximizer is asking him- or herself is not “is this a good outcome?” but “is this the best outcome?”.\nExpanded opportunities for choice may have different effects on the satisficer. The satisficer is looking for something that crosses the threshold of acceptability—something that is good enough. Adding options in a domain in which the satisficer has already encountered something good enough need have no effect; the new options may simply be ignored. With “good enough” rather than the “best” as a criterion, the satisficer will be less inclined to experience regret if it turns out that an option better than the chosen one was available. And if no satisfactory option has been encountered in a domain, added options will provide new possibilities for finding something that crosses the “good enough” threshold. Thus, the risk of being made worse off by added options may be minimal for satisficers.\nSupporting Literature :-  Maximisers vs Satisficing  Can people feel worse off as the options they face increase? The present studies suggest that some people\u0026ndash;maximizers\u0026ndash;can. Study 1 reported a Maximization Scale, which measures individual differences in desire to maximize. Seven samples revealed negative correlations between maximization and happiness, optimism, self-esteem, and life satisfaction, and positive correlations between maximization and depression, perfectionism, and regret. Study 2 found maximizers less satisfied than non-maximizers (satisficers) with consumer decisions, and more likely to engage in social comparison. Study 3 found maximizers more adversely affected by upward social comparison. Study 4 found maximizers more sensitive to regret and less satisfied in an ultimatum bargaining game. The interaction between maximizing and choice is discussed in terms of regret, adaptation, and self-blame.\n The deliberation-without-attention effect  Contrary to conventional wisdom, it is not always advantageous to engage in thorough conscious deliberation before choosing. On the basis of recent insights into the characteristics of conscious and unconscious thought, we tested the hypothesis that simple choices (such as between different towels or different sets of oven mitts) indeed produce better results after conscious thought, but that choices in complex matters (such as between different houses or different cars) should be left to unconscious thought. Named the \u0026ldquo;deliberation-without-attention\u0026rdquo; hypothesis, it was confirmed in four studies on consumer choice, both in the laboratory as well as among actual shoppers, that purchases of complex products were viewed more favorably when decisions had been made in the absence of attentive deliberation.\n Overchoice and Assortment Type: When and Why Variety Backfires  It has long been thought that product variety is beneficial to consumers. Given heterogeneity in tastes across consumers and variety-seeking tendencies within consumers, a wider assortment should better meet the diverse preferences of consumers than a narrower assortment. Thus, a retailer that increases its selection or a manufacturer that expands its brand assortment should increase its market share relative to one that does not. However, recent research calls this “variety-is-good” belief into question. In cases where choice deferral is an option, adding a second attractive alternative to what had been a one-alternative consideration set has been shown to increase the frequency of not making a choice. Given these conflicting perspectives, this paper considers the impact of product assortment in a competitive brand context and asks “when” and “why” an increasing assortment might prove detrimental to brand choice.\nOperational Definitions :-  Maximisation Scale:  The statements in the maximisation questionnaire distinguish maximisers from satisficers. Subjects rate themselves from 1 to 7, from “completely disagree” to “completely agree”, on each statement. People whose average rating is higher than 4 are considered to be maximisers and others to be satisficers..\n Regret Scale:  The regret scale consists of five items and makes use of the same seven point rating scale. It assesses how individuals feel after having made a decision and whether they experience lingering doubt about their choice or regret over what they have missed out on.\nHypothesis :-  Null Hypothesis :  The difference in scores of the regret scale before and after making the choices should remain zero.\n Hypothesis 1 :  As number of choices presented to the subject increases, their satisfaction with the decision decreases and their score on the regret scale also increases. This increase is more when the decision is taken by conscious comparison of options as compared to intuitively choosing one of the options.\n Hypothesis 2 :  The change of the score on the regret scale will be more when the subject is a maximiser as compared to when the subject is a satisficer.\nConceptual Variables :-   Independent Variables :\n Number of choices presented to the subject. It contains three levels: 4, 8 or 12 choices. Conscious comparison in taking the decisions. It contains two levels: immediate response (within 5 seconds) and delayed response after comparison.    Dependent Variables :-\n The difference in the scores on the regret scale before and after the choice is made.    Confounds :-\n  Study is only conducted on college going students : Can be extended easily\n  Participant can be either a maximiser or satisficer : To be taken care of via Maximisation Scale.\n  Mood of the subject at the time of study : Can be made uniform using soothing music\n  The environmental cues at the time of study : Can be Minimised by using a lab based environment\n    Design :- The experiment will be conducted in a questionnaire based manner. The structure of the questionnaire is as follows:\nSection 1 - Maximiser Scale : This section constitutes of 5 questions in which subjects rate themselves from 1 to 7, from “completely disagree” to “completely agree”, on each statement. The average value of responses from this section tell whether the subject is a maximizer or satisficer. The questions are as follows:\n  Section 2 - Initial Regret Scale :- This section constitutes of 5 questions in which subjects rate themselves from 1 to 7, from “completely disagree” to “completely agree”, on each statement. The average value of responses from this section will be taken as the initial regret scale score of the subject. The questions are as follows :\n  Section 3 - Choice based questions :- This section is further divided into 2 subsections: In the first subsection the subject will be familiarized with all the 12 options of the choices from which they will have to choose from in the next subsection. The options will shown in 3 groups of 4. Each group will be visible on the screen for 7 seconds.\nThis section will consist of 3 questions, each of which will contain either 4, 8 or 12 choices to choose from. These options will be a subset of the options which the subjects were familiarised with in the previous subsection. To study the dependence of conscious comparisons on the regret score, half of the subjects will be told to respond immediately (within 5 seconds) while the other half of the subjects will respond in any amount of time they like.\n    Section 4 - Final Regret Scale :- This section consists of exactly the same questions of section 2. The average value of responses from this section will be taken as the final regret scale score of the subject.\nSection 5 - Satisfaction with decision\nThis section contain a question to find out the level of satisfaction with the decision the subjects made in section 3. The subject have to rate in 1 to 10 from “totally not recommended” to “absolutely recommended” on the following statement.\n How likely are you to recommend your choices regarding the car, data plan and laptop to a close friend or relative.  Statistics and Interpretations :-  Hypothesis 1 :-    Delayed Decision: Subjects with fewer choices are more satisfied as they can take an informed decision without thinking about others, those with 8 choices regretted their decision most due to the feeling of leaving out so many alternatives, those with 12 were again satisfied as they did not think much and did not have time to review each option clearly. Consequently, bell shaped data is obtained.\n  Immediate Decision: The scores remain almost the same with varying number of choices as in each case subjects gave equal thought due to limited time.\n  4 choices presented\n  8 choices presented\n  12 choices presented\n Hypothesis 2 :-    Maximisers vs Satisfiers : The trend obtained is opposite as the data sample is fairly small at present, further there was an uneven proportion of both groups.\nApplications in daily life :-   Buying a laptop: Companies with less number of variants of a product are likely to produce a better customer satisfaction in the process of purchasing.\n  Choosing which T-Shirt to wear: It will be more satisfactory to wear a T-Shirt by choosing it randomly form rather than comparing all the possibilities\n  Analysis a great deal of options is likely to produce a less satisfactory decision as compared to choosing one of them intuitively.\n  ","date":1555286400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555286400,"objectID":"111c78e6a9f4d025310f6c2b6dcb1e39","permalink":"https://ayushmclaren.github.io/post/happiness-is-a-choice/","publishdate":"2019-04-15T00:00:00Z","relpermalink":"/post/happiness-is-a-choice/","section":"post","summary":"Is Happiness a matter of choice? Choice here represents the number of options from which a person has to choose from.","tags":["Psychology"],"title":"Is Happiness a choice?","type":"post"},{"authors":["Ayush Agarwal"],"categories":null,"content":"","date":1555261200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555261200,"objectID":"f1e8fb46ef23eb1b362c2b926488eab0","permalink":"https://ayushmclaren.github.io/talk/happiness/","publishdate":"2019-04-15T19:00:00Z","relpermalink":"/talk/happiness/","section":"talk","summary":"Let's look at what choice does to a person!","tags":["Psychology"],"title":"Is Happiness a choice?","type":"talk"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8962afa7345ff59eeaa993573bbbdf10","permalink":"https://ayushmclaren.github.io/project/external-project5/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/external-project5/","section":"project","summary":"Bayesian Logistic Regression model in R for a Bernoulli likelihood.","tags":["MCMC","Bayesian Stats"],"title":"Bayesian Logisitic regression","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"13ae8ee57147a29e30c594398ea087ea","permalink":"https://ayushmclaren.github.io/project/external-project3/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/external-project3/","section":"project","summary":"Guassian mixture model clustering using EM alogrithm","tags":["MCMC"],"title":"Gaussian-Mixture-Models","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f353811446ead3845cc2bb300f91899a","permalink":"https://ayushmclaren.github.io/project/external-project1/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/external-project1/","section":"project","summary":"SARIMA time series model in python for Monthly Rainfall Data of the last 114 years in India.","tags":["Time Series"],"title":"Time Series and Forecasting","type":"project"}]